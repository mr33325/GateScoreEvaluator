{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8def335d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter The GATE Examination Year: 2022\n",
      "Total Marks Obtained: 32.0/100\n",
      "HTML page created at:  C:/Users/mr333/Documents/Python Scripts/Archive/2022/Test_Report_2022.html\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import webbrowser\n",
    "\n",
    "exam_year= input(\"Enter The GATE Examination Year: \")\n",
    "\n",
    "# Get the current working directory and set the file path\n",
    "current_directory = os.getcwd()\n",
    "current_directory =current_directory.replace('\\\\', '/')\n",
    "base_path= 'Archive/'+ exam_year +'/'\n",
    "answer_sheet= base_path + 'answer_sheet_' + exam_year +'.xlsx'\n",
    "answer_key= base_path + 'answer_key_' + exam_year +'.xlsx'\n",
    "report_path= base_path + 'Test_Report_' + exam_year +'.html'\n",
    "\n",
    "# Load the answer sheet and answer key\n",
    "answer_sheet_df = pd.read_excel(answer_sheet, usecols=['Q. No.', 'Answer'])\n",
    "answer_key_df = pd.read_excel(answer_key, usecols=['Q. No.', 'Question Type', 'Key', 'Mark'])\n",
    "\n",
    "# Merge the answer sheet and answer key on question number\n",
    "merged_df = pd.merge(answer_sheet_df, answer_key_df, on='Q. No.')\n",
    "merged_df['Colour']=None \n",
    "correct= []\n",
    "wrong= []\n",
    "not_attempted= []\n",
    "\n",
    "# Function to calculate marks based on the given rules\n",
    "def calculate_marks(row):\n",
    "    if row['Question Type'] == 'MCQ':\n",
    "        if row['Key'] == 'MTA':\n",
    "            correct.append(row['Q. No.'])\n",
    "            return row['Mark']\n",
    "        elif pd.isnull(row['Answer']):\n",
    "            not_attempted.append(row['Q. No.'])\n",
    "            return 0\n",
    "        elif row['Answer'] == row['Key']:\n",
    "            correct.append(row['Q. No.'])\n",
    "            return row['Mark']\n",
    "        else:\n",
    "            row['Colour']='R'\n",
    "            wrong.append(row['Q. No.'])\n",
    "            return -1 / 3 if row['Mark'] == 1 else -2 / 3\n",
    "    elif row['Question Type'] == 'MSQ':\n",
    "        if pd.isnull(row['Answer']):\n",
    "            not_attempted.append(row['Q. No.'])\n",
    "            return 0\n",
    "        \n",
    "        given_answer_list = row['Answer'].split(', ')  # Assuming answers are separated by ', ' in the answer sheet\n",
    "        key_list = row['Key'].split(', ')  # Assuming keys are separated by ', ' in the answer key\n",
    "        \n",
    "        if len(given_answer_list)==len(key_list) and all(answer in key_list for answer in given_answer_list):\n",
    "            correct.append(row['Q. No.'])\n",
    "            return row['Mark']\n",
    "        else:\n",
    "            row['Colour']='R'\n",
    "            wrong.append(row['Q. No.'])\n",
    "            return 0\n",
    "    elif row['Question Type'] == 'NAT':\n",
    "        if pd.isnull(row['Answer']):\n",
    "            not_attempted.append(row['Q. No.'])\n",
    "            return 0\n",
    "        \n",
    "        if \"OR\" in row['Key']:\n",
    "            range_ans = list(set(float(value) for value in re.split(r'\\s+to\\s+|\\s+OR\\s+', row['Key'])))\n",
    "            answer = float(row['Answer'])\n",
    "            \n",
    "            if answer in range_ans:\n",
    "                correct.append(row['Q. No.'])\n",
    "                return row['Mark']\n",
    "            else:\n",
    "                row['Colour']='R'\n",
    "                wrong.append(row['Q. No.'])\n",
    "                return 0\n",
    "\n",
    "        else:\n",
    "            range_start, range_end = map(float, row['Key'].split(' to '))\n",
    "            answer = float(row['Answer'])\n",
    "            \n",
    "            if range_start <= answer <= range_end:\n",
    "                correct.append(row['Q. No.'])\n",
    "                return row['Mark']\n",
    "            else:\n",
    "                row['Colour']='R'\n",
    "                wrong.append(row['Q. No.'])\n",
    "                return 0\n",
    "\n",
    "\n",
    "# Apply the calculate_marks function to each row and calculate total marks\n",
    "merged_df['Obtained Marks'] = merged_df.apply(calculate_marks, axis=1)\n",
    "\n",
    "# Calculate total marks\n",
    "total_marks = merged_df['Obtained Marks'].sum()\n",
    "\n",
    "# Print the total marks\n",
    "print('Total Marks Obtained: '+ str(total_marks) + '/100')\n",
    "merged_df = merged_df[['Q. No.', 'Answer', 'Key', 'Question Type', 'Mark', 'Obtained Marks', 'Colour']]\n",
    "for i in correct:\n",
    "    merged_df.loc[i-1, 'Colour']= 'G'\n",
    "for i in wrong:\n",
    "    merged_df.loc[i-1, 'Colour']= 'R'\n",
    "for i in not_attempted:\n",
    "    merged_df.loc[i-1, 'Colour']= 'Y'\n",
    "    \n",
    "#merged_df.to_excel(\"MarksData.xlsx\")\n",
    "#merged_df.to_json('MarksData.json')\n",
    "\n",
    "\n",
    "###--------------------------------------- HTML Rendering---------------------------------------------------------- ###\n",
    "correct_questions= correct\n",
    "wrong_questions= wrong\n",
    "not_attempted_questions= not_attempted\n",
    "# Calculate additional statistics\n",
    "total_questions = len(correct_questions) + len(wrong_questions) + len(not_attempted_questions)\n",
    "questions_attempted = len(correct_questions) + len(wrong_questions)  # Corrected this line\n",
    "percentage_correct = (len(correct_questions) / questions_attempted) * 100 if questions_attempted > 0 else 0\n",
    "percentage_wrong = (len(wrong_questions) / questions_attempted) * 100 if questions_attempted > 0 else 0\n",
    "percentage_not_attempted = (len(not_attempted_questions) / total_questions) * 100\n",
    "\n",
    "# Create HTML content (transposed table with additional statistics)\n",
    "with open(\"index.html\", \"r\") as html_file:\n",
    "    html_content = html_file.read()\n",
    "\n",
    "# Format question lists for HTML display\n",
    "correct_str = \", \".join(map(str, correct_questions))\n",
    "wrong_str = \", \".join(map(str, wrong_questions))\n",
    "not_attempted_str = \", \".join(map(str, not_attempted_questions))\n",
    "\n",
    "table= merged_df.to_html(index=False)\n",
    "table= table.replace('<table border=\"1\" class=\"dataframe\">', '<table id=\"myTable\" class=\"table table-bordered table-sm\">')\n",
    "table= table.replace('<tr style=\"text-align: right;\">', '<tr>')\n",
    "\n",
    "# Load Js script file\n",
    "with open(\"script.js\", \"r\") as js_file:\n",
    "    table_js = js_file.read()\n",
    "\n",
    "# Populate HTML content with formatted question numbers and statistics\n",
    "html_content = html_content.format(exam_year, total_marks, correct_str, wrong_str, not_attempted_str,\n",
    "                                   total_questions, questions_attempted,\n",
    "                                   len(correct_questions), percentage_correct, \n",
    "                                   len(wrong_questions), percentage_wrong,\n",
    "                                   len(not_attempted_questions), percentage_not_attempted, table, table_js)\n",
    "\n",
    "# Write the HTML content to a file\n",
    "with open(report_path, \"w\") as html_file:\n",
    "    html_file.write(html_content)\n",
    "\n",
    "report_path = current_directory + '/' + report_path\n",
    "print(\"HTML page created at: \", report_path)\n",
    "webbrowser.open(report_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901686ea",
   "metadata": {},
   "source": [
    "### Add the topics that need special attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967ff9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the key point or Enter 0 to exit: Big O Notation\n",
      "Enter the key point or Enter 0 to exit: Hashing\n",
      "Enter the key point or Enter 0 to exit: Semaphore\n",
      "Enter the key point or Enter 0 to exit: Trace of Matrix\n",
      "Enter the key point or Enter 0 to exit: LU Decomposition\n",
      "Enter the key point or Enter 0 to exit: IEEE754\n",
      "Enter the key point or Enter 0 to exit: Recurrence relation\n"
     ]
    }
   ],
   "source": [
    "\n",
    "badge=''\n",
    "spans=''\n",
    "while(1):\n",
    "    badge= input(\"Enter the key point or Enter 0 to exit: \")\n",
    "    if(badge=='0'):\n",
    "        break\n",
    "    spans= spans + '<span class=\"badge bg-primary\">' + badge + '</span> '\n",
    "    \n",
    "html_content= html_content.replace('#null#', spans + '#null#')\n",
    "with open(report_path, \"w\") as html_file:\n",
    "    html_file.write(html_content)\n",
    "webbrowser.open(report_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb882d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
